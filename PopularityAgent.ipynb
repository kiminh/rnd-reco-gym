{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `action`, is a number between `0` and `num_products - 1` that references the index of the product recommended.\n",
    "- `observation` will either be `None` or a session of Organic data, showing the index of products the user views.\n",
    "- `reward` is 0 if the user does not click on the recommended product and 1 if they do. Notice that when a user clicks on a product (Wherever the reward is 1), they start a new Organic session.\n",
    "- `done` is a True/False flag indicating if the episode (aka user's timeline) is over.\n",
    "- `info` currently not used, so it is always an empty dictionary.\n",
    "\n",
    "Also, notice that the first `action` is `None`.  In our implementation, the agent observes Organic behaviour before\n",
    "recommending anything.\n",
    "\n",
    "The agent records merely how many times a user sees each product organically,\n",
    "then when required to make a recommendation, the agent chooses a product randomly in proportion with\n",
    "a number of times the user has viewed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym, recogym\n",
    "\n",
    "# env_0_args is a dictionary of default parameters (i.e. number of products)\n",
    "from recogym import env_1_args, Configuration\n",
    "\n",
    "# You can overwrite environment arguments here:\n",
    "env_1_args['random_seed'] = 42\n",
    "\n",
    "# Initialize the gym for the first time by calling .make() and .init_gym()\n",
    "env = gym.make('reco-gym-v1')\n",
    "env.init_gym(env_1_args)\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "from recogym.agents import Agent\n",
    "\n",
    "# Define an Agent class.\n",
    "class PopularityAgent(Agent):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        \n",
    "        super(PopularityAgent, self).__init__(config) # Set number of products as an attribute of the Agent.\n",
    "\n",
    "        self.organic_views = np.zeros(self.config.num_products) # Track number of times each item viewed in Organic session.\n",
    "\n",
    "    def train(self, observation, action, reward, done):\n",
    "\n",
    "        # Train method learns from a tuple of data. This method can be called for offline or online learning\n",
    "        # Adding organic session to organic view counts.\n",
    "\n",
    "        if observation:\n",
    "            for session in observation.sessions():\n",
    "                self.organic_views[session['v']] += 1\n",
    "\n",
    "    def act(self, observation, reward, done):\n",
    "\n",
    "        # Act method returns an action - based on current observation and past history\n",
    "        # Choosing action randomly in proportion with number of views.\n",
    "\n",
    "        prob = self.organic_views / sum(self.organic_views)\n",
    "        action = choice(self.config.num_products, p = prob)\n",
    "\n",
    "        return {\n",
    "            **super().act(observation, reward, done),\n",
    "            **{\n",
    "                'a': action,\n",
    "                'ps': prob[action]\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click Through Rate: 0.0126\n"
     ]
    }
   ],
   "source": [
    "# Instantiate instance of PopularityAgent class.\n",
    "num_products = 10\n",
    "agent = PopularityAgent(Configuration({\n",
    "    **env_1_args,\n",
    "    'num_products': num_products,\n",
    "}))\n",
    "\n",
    "# Resets random seed back to 42, or whatever we set it to in env_0_args.\n",
    "env.reset_random_seed()\n",
    "\n",
    "# Train on 1000 users offline.\n",
    "num_offline_users = 1000\n",
    "\n",
    "for _ in range(num_offline_users):\n",
    "\n",
    "    # Reset env and set done to False.\n",
    "    env.reset()\n",
    "    done = False\n",
    "\n",
    "    observation, reward, done = None, 0, False\n",
    "    while not done:\n",
    "        old_observation = observation\n",
    "        action, observation, reward, done, info = env.step_offline(observation, reward, done)\n",
    "        agent.train(old_observation, action, reward, done)\n",
    "\n",
    "# Train on 100 users online and track click through rate.\n",
    "num_online_users = 100\n",
    "num_clicks, num_events = 0, 0\n",
    "\n",
    "for _ in range(num_online_users):\n",
    "\n",
    "    # Reset env and set done to False.\n",
    "    env.reset()\n",
    "    observation, _, done, _ = env.step(None)\n",
    "    reward = None\n",
    "    done = None\n",
    "    while not done:\n",
    "        action = agent.act(observation, reward, done)\n",
    "        observation, reward, done, info = env.step(action['a'])\n",
    "\n",
    "        # Used for calculating click through rate.\n",
    "        num_clicks += 1 if reward == 1 and reward is not None else 0\n",
    "        num_events += 1\n",
    "\n",
    "ctr = num_clicks / num_events\n",
    "\n",
    "print(f\"Click Through Rate: {ctr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our Popularity Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import gym, recogym\n",
    "from recogym import env_1_args\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "env_1_args['random_seed'] = 42\n",
    "\n",
    "env = gym.make('reco-gym-v1')\n",
    "env.init_gym(env_1_args)\n",
    "\n",
    "num_products = env_1_args['num_products']\n",
    "\n",
    "popularity_agent = PopularityAgent(Configuration(env_1_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Organic Users: 0it [00:00, ?it/s]\n",
      "Users:   0%|          | 5/1000 [00:00<00:20, 47.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START: Agent Training #0\n",
      "START: Agent Training @ Epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Users: 100%|██████████| 1000/1000 [00:18<00:00, 53.83it/s]\n",
      "Organic Users: 0it [00:00, ?it/s]\n",
      "Users:   0%|          | 2/1000 [00:00<00:52, 18.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END: Agent Training @ Epoch #0 (18.588746070861816s)\n",
      "START: Agent Evaluating @ Epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Users: 100%|██████████| 1000/1000 [00:19<00:00, 52.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END: Agent Evaluating @ Epoch #0 (19.2580349445343s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.014049314459026383, 0.01324351763294106, 0.014886678833290312)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Credible interval of the CTR median and 0.025 0.975 quantile.\n",
    "\n",
    "recogym.test_agent(deepcopy(env), deepcopy(popularity_agent), 1000, 1000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}