{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Agents List:\n",
    "\n",
    "- Fully static recommendation Agent\n",
    "- Simple random recommendation Agent\n",
    "- Logistic regression Agent\n",
    "- Greedy bandit Agent\n",
    "- Greedy organic Agent\n",
    "- CF SVD Agent\n",
    "- Organic MF agent\n",
    "- Bandit MF Agent\n",
    "- Bandit Regression Agent\n",
    "- Organic user count Agent\n",
    "- Neural network Ips Agent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Up until now, we have primarily focused on:\n",
    "- The differences between organic and bandit feedback, and how to properly exploit these signals for model evaluation\n",
    "- Building a model either entirely off of either organic, or bandit feedback\n",
    "- Feature engineering methods in combination with Logistic Regression to properly predict clicks\n",
    "\n",
    "However, we haven't yet looked into combining the organic and the bandit signal to get the best of both worlds.\n",
    "In this notebook, we show a simple example that combines an embedding-based approach (SVD) on the organic signal, with a simple Logistic Regression-based model that predicts whether a given user will interact with a recommendation, should we show it.\n",
    "In conclusion, we show that properly combining these different types of feedback yields a significant gain in model accuracy."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Environment Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random.mtrand import RandomState\n",
    "from recogym import Configuration\n",
    "from recogym.agents import Agent\n",
    "from scipy.special import logsumexp\n",
    "import pandas as pd\n",
    "from scipy.stats.distributions import beta\n",
    "from copy import deepcopy\n",
    "from recogym.agents import OrganicUserEventCounterAgent, organic_user_count_args\n",
    "\n",
    "from recogym.envs.observation import Observation\n",
    "from recogym.agents import RandomAgent, random_args\n",
    "from recogym import verify_agents, verify_agents_IPS\n",
    "from recogym.evaluate_agent import plot_verify_agents, verify_agents_recall_at_k\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from recogym import env_1_args, Configuration\n",
    "\n",
    "# Set style for pretty plots\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "P = 16 # Number of Products\n",
    "U = 5000 # Number of Users\n",
    "\n",
    "# You can overwrite environment arguments here:\n",
    "env_1_args['random_seed'] = 42\n",
    "env_1_args['num_products']= P\n",
    "env_1_args['phi_var']=0.0\n",
    "env_1_args['number_of_flips']=8\n",
    "env_1_args['sigma_mu_organic'] = 0.0\n",
    "env_1_args['sigma_omega']=0\n",
    "#env_1_args['normalize_beta']=True\n",
    "# Initialize the gym for the first time by calling .make() and .init_gym()\n",
    "env = gym.make('reco-gym-v1')\n",
    "env.init_gym(env_1_args)\n",
    "\n",
    "env.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generate RecSys logs for U users\n",
    "reco_log = env.generate_logs(U)\n",
    "reco_log.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining the Agent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The critical part of our agent is a Logistic Regression model, that predicts whether a user will click a given recommendation, based on some features.\n",
    "In what follows, we present an overview of these simple features.\n",
    "\n",
    "- The first `K` features are the latent components representing the user state. As proposed in the well-known SVD++ approach and aligned with the previous notebooks, we decompose the item co-count matrix and represent a user with the average embedding of the items in her history.\n",
    "- Following this, we embed the specific item we want to recommend as a one-hot-encoded sparse vector of length `P`.\n",
    "- In order to further exploit the organic signal: we include a count of organic views for the given item in the training set, and the result of the dot-product between the user- and item-embedding.\n",
    "\n",
    "As discussed previously, we need cross-interaction between the user- and item-features to ensure a personalised approach.\n",
    "With this in mind, we take the Kronecker-product between the first `K` and last `P+2` features in order to obtain our final `KP+2` features.\n",
    "\n",
    "We make our agent greedy, i.e. it will always take the action it deems to have the highest probability of generating a click, without any exploratory behaviour for lesser actions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def create_embeddings(reco_log, U, P, K = 5):\n",
    "    organic_reco_log = reco_log[reco_log['z']=='organic']\n",
    "    counts = np.zeros((U,P))\n",
    "\n",
    "    for u in range(U):\n",
    "        counts[u,:] = to_categorical(np.array(organic_reco_log[organic_reco_log['u']==u].v,dtype=int),P).sum(0)\n",
    "\n",
    "    counts_above_zero = 1.*(counts>0) # above zero counts only\n",
    "    co_counts = np.matmul(counts_above_zero.T,counts_above_zero)\n",
    "\n",
    "    w , v = np.linalg.eig(co_counts)\n",
    "    idx = np.argsort(w)[::-1]\n",
    "    v = np.real(v[:,idx])\n",
    "    w = np.real(w[idx])\n",
    "\n",
    "    wdash = np.zeros_like(w)\n",
    "\n",
    "    wdash[0:K] = w[0:K]\n",
    "    embeddings = np.matmul(v,np.sqrt(np.diag(wdash)))[:,0:K] # keep the non-zero components\n",
    "    return embeddings\n",
    "\n",
    "class SVDLogRegAgent(Agent):\n",
    "    def __init__(self, config, reco_log, U = U, P = P, K = 5, greedy = False):\n",
    "        super(SVDLogRegAgent, self).__init__(config)\n",
    "        self.rng = RandomState(self.config.random_seed)\n",
    "        self.organic_views = np.zeros(self.config.num_products)\n",
    "        assert(P >= K)\n",
    "        assert(reco_log.v.max() < P)\n",
    "        self.K = K\n",
    "        self.history_length = 0\n",
    "        self.greedy = greedy\n",
    "        self.item_popularities = defaultdict(int)\n",
    "        self.train(reco_log, U, P)\n",
    "\n",
    "    def train(self, reco_log, U, P):\n",
    "        # Generate item embeddings by SVD on item co-count matrix\n",
    "        self.embeddings = create_embeddings(reco_log, U, P, self.K)\n",
    "\n",
    "        # Compute item popularities\n",
    "        for row in reco_log.loc[reco_log['z'] == 'organic'].itertuples():\n",
    "            self.item_popularities[int(row.v)] += 1\n",
    "\n",
    "        # Generate feature-matrix X to train on\n",
    "        X = []\n",
    "        y = []\n",
    "        uid = 0\n",
    "        uemb = np.zeros(self.K)\n",
    "        ucnt = 0\n",
    "        for row in reco_log.itertuples():\n",
    "            # Do we have a new user?\n",
    "            if row.u != uid:\n",
    "                # Reset the embedding\n",
    "                uid = row.u\n",
    "                uemb = np.zeros(self.K)\n",
    "                ucnt = 0\n",
    "            # Is this an organic event?\n",
    "            if row.z == 'organic':\n",
    "                # Update the user embedding\n",
    "                uemb += self.embeddings[int(row.v),:]\n",
    "                ucnt += 1\n",
    "            elif row.z == 'bandit':\n",
    "                # Pad the user embedding with zeros\n",
    "                #features = np.hstack((uemb,np.zeros(P)))\n",
    "                # One-hot encode the item in the last P columns\n",
    "                #features[self.K + int(row.a)] = 1.\n",
    "                aemb = np.zeros(P + 2)\n",
    "                aemb[int(row.a)] = 1.\n",
    "                aemb[-2] = self.item_popularities[int(row.a)]\n",
    "                dot = np.matmul(self.embeddings[int(row.a),:],uemb/ucnt)\n",
    "                aemb[-1] = dot\n",
    "                features = np.kron(uemb/ucnt, aemb)\n",
    "                X.append(features)\n",
    "                y.append(row.c)\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        # Train Logistic Regression model\n",
    "        self.model = LogisticRegression(solver = 'liblinear',\n",
    "                                        max_iter = 200).fit(X,y)\n",
    "\n",
    "    def observe(self, observation):\n",
    "        for session in observation.sessions():\n",
    "            self.user_embedding += self.embeddings[session['v'],:]\n",
    "            self.history_length += 1\n",
    "\n",
    "    def act(self, observation, reward, done):\n",
    "        \"\"\"Act method returns an Action based on current observation and past history\"\"\"\n",
    "        self.observe(observation)\n",
    "\n",
    "        # Generate a prediction for every possible action\n",
    "        X = []\n",
    "        for a in range(self.embeddings.shape[0]):\n",
    "            # Pad the user embedding with zeros\n",
    "            #features = np.hstack((self.user_embedding,np.zeros(self.embeddings.shape[0])))\n",
    "            # One-hot encode the item in the last P columns\n",
    "            #features[self.K + a] = 1.\n",
    "            aemb = np.zeros(self.embeddings.shape[0] + 2)\n",
    "            aemb[int(a)] = 1.\n",
    "            aemb[-2] = self.item_popularities[int(a)]\n",
    "            dot = np.matmul(self.embeddings[int(a),:],(self.user_embedding/self.history_length))\n",
    "            aemb[-1] = dot\n",
    "            features = np.kron((self.user_embedding/self.history_length), aemb)\n",
    "            X.append(features)\n",
    "        prob = self.model.predict_log_proba(np.asarray(X))[:,1]\n",
    "        prob = np.exp(prob-logsumexp(prob))\n",
    "\n",
    "        if self.greedy:\n",
    "            a = np.argmax(prob)\n",
    "            prob = np.zeros(prob.shape)\n",
    "            prob[a] = 1.\n",
    "\n",
    "        # Sample action according to probability distribution\n",
    "        action = self.rng.choice(self.config.num_products, p = prob)\n",
    "        return {\n",
    "            **super().act(observation, reward, done),\n",
    "            **{\n",
    "                'a': action,\n",
    "                'ps': prob[action],\n",
    "                'ps-a': prob,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def reset(self):\n",
    "        self.user_embedding = np.zeros(self.K)\n",
    "        self.history_length = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "organic_counter_agent = OrganicUserEventCounterAgent(Configuration({\n",
    "            **organic_user_count_args,\n",
    "            **env_1_args,\n",
    "            'select_randomly': True,\n",
    "        }))\n",
    "\n",
    "random_args['num_products'] = P\n",
    "agent_rand = RandomAgent(Configuration({**env_1_args, **random_args,}))\n",
    "\n",
    "SVDLR = SVDLogRegAgent(Configuration(env_1_args), reco_log, U, P, 8, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A/B-Test Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We evaluate our new model by simulating an A/B-test against two baselines: the random agent and the popularity based agent.\n",
    "As we have seen before, although the popularity baseline is naive and simple, it is not always that trivial to beat in a first try."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_AB = verify_agents(env, U, {' Random': agent_rand, 'Popularity': organic_counter_agent, 'SVD-LR': SVDLR})\n",
    "result_AB"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plot_verify_agents(result_AB)\n",
    "plt.ylabel('CTR')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On average, we see a 14% improvement in click-through rate when comparing the popularity baseline with our new SVD-LR model.\n",
    "This difference might seem small, but you can imagine that a 14% increase in a million-dollar business has quite a big impact.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}