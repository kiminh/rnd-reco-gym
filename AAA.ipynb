{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDD-based Agent with LogReg on Bandit Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until now, we have primarily focused on:\n",
    "- The differences between organic and bandit feedback, and how to properly exploit these signals for model evaluation\n",
    "- Building a model either entirely off of either organic, or bandit feedback\n",
    "- Feature engineering methods in combination with Logistic Regression to properly predict clicks\n",
    "\n",
    "However, we haven't yet looked into combining the organic and the bandit signal to get the best of both worlds.\n",
    "In this notebook, we show a simple example that combines an embedding-based approach (SVD) on the organic signal, with a simple Logistic Regression-based model that predicts whether a given user will interact with a recommendation, should we show it.\n",
    "In conclusion, we show that properly combining these different types of feedback yields a significant gain in model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/usr/local/Cellar/python@3.8/3.8.2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/usr/local/Cellar/python@3.8/3.8.2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: dlopen(/usr/local/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: ____chkstk_darwin\n  Referenced from: /usr/local/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.2.dylib\n  Expected in: /usr/lib/libSystem.B.dylib\n in /usr/local/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.2.dylib\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 58\u001B[0;31m   \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpywrap_tensorflow_internal\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     59\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     27\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0m_mod\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 28\u001B[0;31m     \u001B[0m_pywrap_tensorflow_internal\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mswig_import_helper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     29\u001B[0m     \u001B[0;32mdel\u001B[0m \u001B[0mswig_import_helper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001B[0m in \u001B[0;36mswig_import_helper\u001B[0;34m()\u001B[0m\n\u001B[1;32m     23\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 24\u001B[0;31m                 \u001B[0m_mod\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_module\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'_pywrap_tensorflow_internal'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpathname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdescription\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     25\u001B[0m             \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/Cellar/python@3.8/3.8.2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/imp.py\u001B[0m in \u001B[0;36mload_module\u001B[0;34m(name, file, filename, details)\u001B[0m\n\u001B[1;32m    241\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 242\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mload_dynamic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    243\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mtype_\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mPKG_DIRECTORY\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/Cellar/python@3.8/3.8.2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/imp.py\u001B[0m in \u001B[0;36mload_dynamic\u001B[0;34m(name, path, file)\u001B[0m\n\u001B[1;32m    341\u001B[0m             name=name, loader=loader, origin=path)\n\u001B[0;32m--> 342\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_load\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    343\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mImportError\u001B[0m: dlopen(/usr/local/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: ____chkstk_darwin\n  Referenced from: /usr/local/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.2.dylib\n  Expected in: /usr/lib/libSystem.B.dylib\n in /usr/local/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.2.dylib",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-faa8b7f124fa>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mrecogym\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mverify_agents\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverify_agents_IPS\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mrecogym\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate_agent\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mplot_verify_agents\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverify_agents_recall_at_k\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mto_categorical\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mgym\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0msys\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0m_sys\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 41\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtools\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmodule_util\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0m_module_util\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     42\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutil\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlazy_loader\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mLazyLoader\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0m_LazyLoader\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 50\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpywrap_tensorflow\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     51\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[0;31m# Protocol buffers\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     67\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0msome\u001B[0m \u001B[0mcommon\u001B[0m \u001B[0mreasons\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0msolutions\u001B[0m\u001B[0;34m.\u001B[0m  \u001B[0mInclude\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mentire\u001B[0m \u001B[0mstack\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     68\u001B[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001B[0;32m---> 69\u001B[0;31m   \u001B[0;32mraise\u001B[0m \u001B[0mImportError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     70\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[0;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mImportError\u001B[0m: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/usr/local/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/usr/local/Cellar/python@3.8/3.8.2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/usr/local/Cellar/python@3.8/3.8.2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: dlopen(/usr/local/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: ____chkstk_darwin\n  Referenced from: /usr/local/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.2.dylib\n  Expected in: /usr/lib/libSystem.B.dylib\n in /usr/local/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.2.dylib\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random.mtrand import RandomState\n",
    "from recogym import Configuration\n",
    "from recogym.agents import Agent\n",
    "from scipy.special import logsumexp\n",
    "import pandas as pd\n",
    "from scipy.stats.distributions import beta\n",
    "from copy import deepcopy\n",
    "from recogym.agents import OrganicUserEventCounterAgent, organic_user_count_args\n",
    "\n",
    "from recogym.envs.observation import Observation\n",
    "from recogym.agents import RandomAgent, random_args\n",
    "from recogym import verify_agents, verify_agents_IPS\n",
    "from recogym.evaluate_agent import plot_verify_agents, verify_agents_recall_at_k\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from recogym import env_1_args, Configuration\n",
    "\n",
    "# Set style for pretty plots\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "P = 16 # Number of Products\n",
    "U = 5000 # Number of Users\n",
    "\n",
    "# You can overwrite environment arguments here:\n",
    "env_1_args['random_seed'] = 42\n",
    "env_1_args['num_products']= P\n",
    "env_1_args['phi_var']=0.0\n",
    "env_1_args['number_of_flips']=8\n",
    "env_1_args['sigma_mu_organic'] = 0.0\n",
    "env_1_args['sigma_omega']=0\n",
    "#env_1_args['normalize_beta']=True\n",
    "# Initialize the gym for the first time by calling .make() and .init_gym()\n",
    "env = gym.make('reco-gym-v1')\n",
    "env.init_gym(env_1_args)\n",
    "\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate RecSys logs for U users\n",
    "reco_log = env.generate_logs(U)\n",
    "reco_log.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The critical part of our agent is a Logistic Regression model, that predicts whether a user will click a given recommendation, based on some features.\n",
    "In what follows, we present an overview of these simple features.\n",
    "\n",
    "- The first `K` features are the latent components representing the user state. As proposed in the well-known SVD++ approach and aligned with the previous notebooks, we decompose the item co-count matrix and represent a user with the average embedding of the items in her history.\n",
    "- Following this, we embed the specific item we want to recommend as a one-hot-encoded sparse vector of length `P`.\n",
    "- In order to further exploit the organic signal: we include a count of organic views for the given item in the training set, and the result of the dot-product between the user- and item-embedding.\n",
    "\n",
    "As discussed previously, we need cross-interaction between the user- and item-features to ensure a personalised approach.\n",
    "With this in mind, we take the Kronecker-product between the first `K` and last `P+2` features in order to obtain our final `KP+2` features.\n",
    "\n",
    "We make our agent greedy, i.e. it will always take the action it deems to have the highest probability of generating a click, without any exploratory behaviour for lesser actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def create_embeddings(reco_log, U, P, K = 5):\n",
    "    organic_reco_log = reco_log[reco_log['z']=='organic']\n",
    "    counts = np.zeros((U,P))\n",
    "\n",
    "    for u in range(U):\n",
    "        counts[u,:] = to_categorical(np.array(organic_reco_log[organic_reco_log['u']==u].v,dtype=int),P).sum(0)\n",
    "\n",
    "    counts_above_zero = 1.*(counts>0) # above zero counts only\n",
    "    co_counts = np.matmul(counts_above_zero.T,counts_above_zero)\n",
    "    \n",
    "    w , v = np.linalg.eig(co_counts)\n",
    "    idx = np.argsort(w)[::-1] \n",
    "    v = np.real(v[:,idx])\n",
    "    w = np.real(w[idx])\n",
    "\n",
    "    wdash = np.zeros_like(w)\n",
    "\n",
    "    wdash[0:K] = w[0:K]\n",
    "    embeddings = np.matmul(v,np.sqrt(np.diag(wdash)))[:,0:K] # keep the non-zero components\n",
    "    return embeddings\n",
    "\n",
    "class SVDLogRegAgent(Agent):\n",
    "    def __init__(self, config, reco_log, U = U, P = P, K = 5, greedy = False):\n",
    "        super(SVDLogRegAgent, self).__init__(config)\n",
    "        self.rng = RandomState(self.config.random_seed)\n",
    "        self.organic_views = np.zeros(self.config.num_products)\n",
    "        assert(P >= K)\n",
    "        assert(reco_log.v.max() < P)\n",
    "        self.K = K\n",
    "        self.history_length = 0\n",
    "        self.greedy = greedy\n",
    "        self.item_popularities = defaultdict(int)\n",
    "        self.train(reco_log, U, P)\n",
    "        \n",
    "    def train(self, reco_log, U, P):\n",
    "        # Generate item embeddings by SVD on item co-count matrix\n",
    "        self.embeddings = create_embeddings(reco_log, U, P, self.K)\n",
    "        \n",
    "        # Compute item popularities\n",
    "        for row in reco_log.loc[reco_log['z'] == 'organic'].itertuples():\n",
    "            self.item_popularities[int(row.v)] += 1\n",
    "        \n",
    "        # Generate feature-matrix X to train on\n",
    "        X = []\n",
    "        y = []\n",
    "        uid = 0\n",
    "        uemb = np.zeros(self.K)\n",
    "        ucnt = 0\n",
    "        for row in reco_log.itertuples():\n",
    "            # Do we have a new user?\n",
    "            if row.u != uid:\n",
    "                # Reset the embedding\n",
    "                uid = row.u\n",
    "                uemb = np.zeros(self.K)\n",
    "                ucnt = 0\n",
    "            # Is this an organic event?\n",
    "            if row.z == 'organic':\n",
    "                # Update the user embedding\n",
    "                uemb += self.embeddings[int(row.v),:]\n",
    "                ucnt += 1\n",
    "            elif row.z == 'bandit':\n",
    "                # Pad the user embedding with zeros\n",
    "                #features = np.hstack((uemb,np.zeros(P)))\n",
    "                # One-hot encode the item in the last P columns\n",
    "                #features[self.K + int(row.a)] = 1.\n",
    "                aemb = np.zeros(P + 2)\n",
    "                aemb[int(row.a)] = 1.\n",
    "                aemb[-2] = self.item_popularities[int(row.a)]\n",
    "                dot = np.matmul(self.embeddings[int(row.a),:],uemb/ucnt)\n",
    "                aemb[-1] = dot\n",
    "                features = np.kron(uemb/ucnt, aemb)\n",
    "                X.append(features)\n",
    "                y.append(row.c)\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        \n",
    "        # Train Logistic Regression model\n",
    "        self.model = LogisticRegression(solver = 'liblinear',\n",
    "                                        max_iter = 200).fit(X,y)\n",
    "    \n",
    "    def observe(self, observation):\n",
    "        for session in observation.sessions():\n",
    "            self.user_embedding += self.embeddings[session['v'],:]\n",
    "            self.history_length += 1\n",
    "\n",
    "    def act(self, observation, reward, done):\n",
    "        \"\"\"Act method returns an Action based on current observation and past history\"\"\"\n",
    "        self.observe(observation)\n",
    "\n",
    "        # Generate a prediction for every possible action\n",
    "        X = []\n",
    "        for a in range(self.embeddings.shape[0]):\n",
    "            # Pad the user embedding with zeros\n",
    "            #features = np.hstack((self.user_embedding,np.zeros(self.embeddings.shape[0])))\n",
    "            # One-hot encode the item in the last P columns\n",
    "            #features[self.K + a] = 1.\n",
    "            aemb = np.zeros(self.embeddings.shape[0] + 2)\n",
    "            aemb[int(a)] = 1.\n",
    "            aemb[-2] = self.item_popularities[int(a)]\n",
    "            dot = np.matmul(self.embeddings[int(a),:],(self.user_embedding/self.history_length))\n",
    "            aemb[-1] = dot\n",
    "            features = np.kron((self.user_embedding/self.history_length), aemb)\n",
    "            X.append(features)\n",
    "        prob = self.model.predict_log_proba(np.asarray(X))[:,1]\n",
    "        prob = np.exp(prob-logsumexp(prob))\n",
    "        \n",
    "        if self.greedy:\n",
    "            a = np.argmax(prob)\n",
    "            prob = np.zeros(prob.shape)\n",
    "            prob[a] = 1.\n",
    "        \n",
    "        # Sample action according to probability distribution\n",
    "        action = self.rng.choice(self.config.num_products, p = prob)\n",
    "        return {\n",
    "            **super().act(observation, reward, done),\n",
    "            **{\n",
    "                'a': action,\n",
    "                'ps': prob[action],\n",
    "                'ps-a': prob,\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def reset(self):\n",
    "        self.user_embedding = np.zeros(self.K)\n",
    "        self.history_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organic_counter_agent = OrganicUserEventCounterAgent(Configuration({\n",
    "            **organic_user_count_args,\n",
    "            **env_1_args,\n",
    "            'select_randomly': True,\n",
    "        }))\n",
    "\n",
    "random_args['num_products'] = P\n",
    "agent_rand = RandomAgent(Configuration({**env_1_args, **random_args,}))\n",
    "\n",
    "SVDLR = SVDLogRegAgent(Configuration(env_1_args), reco_log, U, P, 8, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A/B-Test Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate our new model by simulating an A/B-test against two baselines: the random agent and the popularity based agent.\n",
    "As we have seen before, although the popularity baseline is naive and simple, it is not always that trivial to beat in a first try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_AB = verify_agents(env, U, {' Random': agent_rand, 'Popularity': organic_counter_agent})\n",
    "result_AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_verify_agents(result_AB)\n",
    "plt.ylabel('CTR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, we see a 14% improvement in click-through rate when comparing the popularity baseline with our new SVD-LR model.\n",
    "This difference might seem small, but you can imagine that a 14% increase in a million-dollar business has quite a big impact.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}